{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMBD TOP250 Movie Analysis and Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web = 'https://www.imdb.com/chart/top/?ref_=nv_mv_250'\n",
    "web2 = 'https://www.imdb.com/'\n",
    "headers = [\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv2.0.1) Gecko/20100101 Firefox/4.0.1\",\n",
    "        \"Mozilla/5.0 (Windows NT 6.1; rv2.0.1) Gecko/20100101 Firefox/4.0.1\",\n",
    "        \"Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; en) Presto/2.8.131 Version/11.11\",\n",
    "        \"Opera/9.80 (Windows NT 6.1; U; en) Presto/2.8.131 Version/11.11\",\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_0) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11\"]\n",
    "\n",
    "header = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:57.0) Gecko/20100101 Firefox/57.0'}\n",
    "\n",
    "pattern1 = 'Country:(.*) Language:(.*) Rele.*Budget:(.*)\\(.*Gro.*:(.*)Pro.*Co:(.*)See more.*Runtime:(.*)min'\n",
    "pattern2 = 'Country:(.*) Language:(.*) Rele.*Gro.*:(.*)Pro.*Co:(.*)See more.*Runtime:(.*)min'\n",
    "pattern3 = 'Country:(.*) Language:(.*) Rele.*Budget:(.*)\\(.*Pro.*Co:(.*)See more.*Runtime:(.*)min'\n",
    "pattern4 = 'Country:(.*) Language:(.*) Rele.*Gro.*:(.*)Pro.*Co:(.*)See more.*Runtime:(.*)min'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function\n",
    "- Parse the main page of IMBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get soup object\n",
    "def getSoup(url,header):\n",
    "    req = requests.get(url,headers=header)\n",
    "    bs = BeautifulSoup(req.content,'html')\n",
    "    return bs\n",
    "\n",
    "# get data\n",
    "def getData(bs):\n",
    "    data = bs.find('tbody', attrs = {'class': 'lister-list'})\n",
    "    # get titles and urls\n",
    "    film_info = data.find_all('td',attrs={'class':'titleColumn'})\n",
    "    titles =  [k.find('a').text for k in film_info]\n",
    "    urls =  [web2 + k.find('a').attrs['href'][:17] for k in film_info]\n",
    "    years = [k.find('span').text[1:5] for k in film_info]\n",
    "    # get score\n",
    "    score_info = data.find_all('td',attrs={'class':'imdbRating'})\n",
    "    scores = [k.text.replace('\\n','') for k in score_info]\n",
    "    # return data frame\n",
    "    data = pd.DataFrame({'Name':titles,'Score':scores,'Year':years,'Url':urls})      \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Parse the details of movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['USA', 'English', '25000000', '28786657', 'Castle Rock Entertainment', '142']\n",
    "# country, language, budget, gross revenue, production, runtime\n",
    "def getInfo_1(bs,p = pattern1):\n",
    "    info1 = bs.find('div',{'class':'article','id':'titleDetails'}).find_all('div',attrs={'class':'txt-block'})\n",
    "    info2 = ' '.join([s.text.replace('\\n','').strip() for s in info1])\n",
    "    info3 = re.findall(p,info2)\n",
    "    status = 0\n",
    "    if not info3: \n",
    "        info3, status = re.findall(pattern2,info2), 1\n",
    "    if not info3: \n",
    "        info3, status = re.findall(pattern3,info2), 2\n",
    "    d1 = [d.strip() for d in info3[0]]\n",
    "    if len(d1) < 6:\n",
    "        if status == 1:\n",
    "            d1.insert(2,'0')\n",
    "        elif status == 2:\n",
    "            d1.insert(3,'0')\n",
    "    temp = []\n",
    "    for i,n in enumerate(d1):\n",
    "        if i in (2,3):\n",
    "            n = ''.join(re.findall(r'\\d',n))\n",
    "        elif i == 5:\n",
    "            n = ''.join(re.findall(r'\\d',n.split('|')[0]))\n",
    "        temp.append(n)\n",
    "    return temp\n",
    "\n",
    "# ['R','Drama','2236434','7728', '225', 'Two imprisoned men bond over a number of years, finding solace and eventual redemption through acts of common decency.',\n",
    "# ['Frank Darabont'],['Stephen King', 'Frank Darabont'],['Tim Robbins', 'Morgan Freeman', 'Bob Gunton']]\n",
    "# Rating, Genera, Nums of Score, Nums of Review, Nums of critic, Story, Director, Writer, Stars\n",
    "def getInfo_2(bs):\n",
    "    d2 = bs.find('div',{'class':'title_wrapper'}).find_all('div',{'class':'subtext'})\n",
    "    t1 = [info.strip() for i,info in enumerate(d2[0].text.replace('\\n','').split('|')) if i in (0,2)]\n",
    "    d3 = bs.find('div',{'class':'ratings_wrapper'}).a.text\n",
    "    t2 = [''.join(re.findall(r'\\d',d3))]\n",
    "    d4 = bs.find('div',{'class':'titleReviewBarItem titleReviewbarItemBorder'})\n",
    "    d4 = d4.span.text.replace('\\n','').split('|')\n",
    "    t3 = [''.join(re.findall(r'\\d',d)) for d in d4]\n",
    "    d5 = bs.find('div',{'class':'plot_summary'}).find_all('div')\n",
    "    summary = [x.text.strip().replace('\\n','') for x in d5]\n",
    "    t4 = []\n",
    "    for i,n in enumerate(summary):\n",
    "        if i == 1:\n",
    "            names = re.findall(r'Dire.*:(.*)',n)[0].split(',')\n",
    "            res = [i.split('(')[0].strip() for i in names]\n",
    "            n = ', '.join(res)\n",
    "        elif i == 2:\n",
    "            names = re.findall(r'Write.*:(.*)',n)[0].split(',')\n",
    "            res = [i.split('(')[0].strip() for i in names]\n",
    "            if len(res) > 1:\n",
    "                temp = re.findall(r'(.*)\\|',res[1])\n",
    "                if temp: res[1] = temp[0].strip()\n",
    "            n = ', '.join(res)\n",
    "        elif i == 3:\n",
    "            stars = re.findall(r'Stars:(.*)\\|See',n)\n",
    "            res = [s.strip() for s in stars[0].split(',')]\n",
    "            n = ', '.join(res)\n",
    "        t4.append(n)\n",
    "    return t1 + t2 + t3 + t4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the data of main page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = getSoup(web,header)\n",
    "data = getData(bs)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_url = data['Url'].values[0]\n",
    "print(new_url)\n",
    "data['Url'][:5].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the data as 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Name','Country','Language','Budget','Gross_revenue','Production','Runtime','Rating',\n",
    "          'Genre','Nums_score','Nums_review','Nums_critic','Story','Director','Writer','Star']\n",
    "\n",
    "with open(\"test.csv\",\"w\",newline='') as file: \n",
    "    writer = csv.writer(file)\n",
    "    # columns_name\n",
    "    writer.writerow(columns)\n",
    "    for i,u in enumerate(data['Url'][:].values):\n",
    "        page = getSoup(u,header)\n",
    "        detail = getInfo_1(page) + getInfo_2(page)\n",
    "        content = [data['Name'][i]] + detail\n",
    "        writer.writerow(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the test.csv and manually change two odd numbers, then save as data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('data.csv',encoding='latin-1')\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Form a new dataset by merge data and data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(data,data2,how='left',on=['Name'])\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save new dataset as movie.csv for Tableau visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('movie.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,n in enumerate(list(result.columns)):\n",
    "    print(i,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill Nan values as zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = result.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose all text features and merge them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = list(range(4,16)) + list(range(17,20)) + list(range(21,25)) + list(range(28,36))\n",
    "index = set(index)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in range(250):\n",
    "    info = [m for m in list(train.iloc[i,:])]\n",
    "    infos = [m.strip() for i,m in enumerate(info) if i in index and m]\n",
    "    text = ' '.join(infos)\n",
    "    temp.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = train[['Name']]\n",
    "df1['Text'] = temp\n",
    "df1['Text'].apply(lambda x:x.replace(',',''))\n",
    "df1['Text'].apply(lambda x:x.replace('.',''))\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One movie could be represent by one sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in df1['Text'][0:5]:\n",
    "    print(test,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare corpus and build Word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [t.split(' ') for t in temp]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(corpus, size=50, window=5, min_count=1, workers=multiprocessing.cpu_count(),iter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec model's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv['Nolan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The similarity between two words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.similarity('Nolan', 'man')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The most similar ten words of the certain word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar('Nolan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The similarity between two sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.n_similarity(corpus[20],corpus[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = [[0]*250 for _ in range(250)]\n",
    "for i in range(250):\n",
    "    for j in range(250):\n",
    "        ma[i][j] = model.n_similarity(corpus[i],corpus[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matrix(ma)\n",
    "simi_matrix = pd.DataFrame(np.matrix(ma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simi_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommend the most similar movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(name,nums=8):\n",
    "    names = list(data['Name'].values)\n",
    "    index = names.index(name)\n",
    "    vals = list(simi_matrix[index].values)\n",
    "    value = sorted(vals,reverse=True)\n",
    "    res = []\n",
    "    for i in range(1,nums+1):\n",
    "        name_index = vals.index(value[i])\n",
    "        res.append(names[name_index])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend('The Godfather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend('Inception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend('The Lord of the Rings: The Return of the King')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "TV = TfidfVectorizer(max_features=100)\n",
    "X = TV.fit_transform(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new train data for machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = pd.DataFrame.sparse.from_spmatrix(X)\n",
    "train2['Name'] = train['Name'].values\n",
    "train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3 = train[['Name','Score','Year','Gross_revenue','Runtime','Nums_score','Nums_review','Nums_critic']]\n",
    "train3['Score'] = train3['Score'].apply(lambda x:float(str(x)))\n",
    "train3['Year'] = train3['Year'].apply(lambda x:int(str(x)))\n",
    "train3['Gross_revenue'] = train3['Gross_revenue'].apply(lambda x:int(str(x)))\n",
    "train3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Look the correaltion of numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.merge(left=train3,right=train2,on=['Name'])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split X, y and randomly split them to trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in list(train_data.columns) if col not in ('Name','Score')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "X = train_data[cols].values\n",
    "y = train_data['Score'].values\n",
    "rs = ShuffleSplit(n_splits=1, test_size=0.3, random_state=0)\n",
    "rs.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in rs.split(X):\n",
    "    print(\"TRAIN:\", train_index) \n",
    "    print(\"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "score_predictions = lin_reg.predict(X_train)\n",
    "lin_mse = mean_squared_error(y_train, score_predictions)\n",
    "print('Train set: ',lin_mse)\n",
    "score_predictions = lin_reg.predict(X_test)\n",
    "lin_mse = mean_squared_error(y_test, score_predictions)\n",
    "print('Test set: ',lin_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the weights of parameters and R square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for w,c in zip(list(lin_reg.coef_),cols):\n",
    "    temp.append([w,c])\n",
    "temp.sort(key=lambda x:abs(x[0]),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Random Forest Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_predictions = forest_reg.predict(X_train)\n",
    "rf_mse = mean_squared_error(y_train, score_predictions)\n",
    "print('Train set: ',rf_mse)\n",
    "score_predictions = forest_reg.predict(X_test)\n",
    "rf_mse = mean_squared_error(y_test, score_predictions)\n",
    "print('Test set: ',rf_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_reg.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for w,c in zip(list(forest_reg.feature_importances_),cols):\n",
    "    temp.append([w,c])\n",
    "temp.sort(key=lambda x:x[0],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of two model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = data[['Name']]\n",
    "pred_data['Score'] = y\n",
    "pred_data['LR_Predict'] = lin_reg.predict(X)\n",
    "pred_data['RF_Predict'] = forest_reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y, lin_reg.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y, forest_reg.predict(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
